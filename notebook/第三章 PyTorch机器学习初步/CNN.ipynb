{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca33367-f7b0-4f24-99e8-30bcd7f10be3",
   "metadata": {},
   "source": [
    "前面构建了一个最简单的神经网络 MLP（Multilayer Perceptron, 多层感知机），在CIFAR 10准确率在40-50%左右。\n",
    "\n",
    "下面构建一个层数相同的卷积神经网络，进行对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8857154f-e246-47d4-9cae-b4cbffe2c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  '''\n",
    "  A ConvNet with two conv layers.\n",
    "  '''\n",
    "  def __init__(self, input_dim = (3,32,32), kernel_num = (24,12), output_dim = 10): # constructor\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "\n",
    "        # in_channels (int) – Number of channels in the input image \n",
    "        # out_channels (int) – Number of channels produced by the convolution \n",
    "        # kernel_size (int or tuple) – Size of the convolving kernel \n",
    "        # stride (int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "        # padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0\n",
    "        nn.Conv2d(input_dim[0], kernel_num[0], 3, 1, 1), # 内部运算时，三个in_channel的卷积后再累加，得到一个out_channel\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(kernel_num[0], kernel_num[1], 3, 1, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(), # (start_dim=1, end_dim=-1),  \n",
    "        nn.Linear(kernel_num[1]*input_dim[1]*input_dim[2], output_dim)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302ae2b-4297-4f8c-9ebc-c48f5a30edb6",
   "metadata": {},
   "source": [
    "跟前面的MLP模型相比，CNN更好地捕获了像素之间的空间关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f548375a-a307-4f79-900f-fa29ab1f2be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is on: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(dot.exe:18908): Pango-WARNING **: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 11.0.0 (20240428.1522)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"202pt\" height=\"610pt\"\n",
       " viewBox=\"0.00 0.00 202.00 610.25\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 606.25)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-606.25 198,-606.25 198,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-8 8,-560.25 186,-560.25 186,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"39.25\" y=\"-544.85\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">Sequential</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"161.38,-602.25 32.62,-602.25 32.62,-568.25 161.38,-568.25 161.38,-602.25\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"32.62,-568.25 32.62,-602.25 94.38,-602.25 94.38,-568.25 32.62,-568.25\"/>\n",
       "<text text-anchor=\"start\" x=\"37.62\" y=\"-587.75\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"47\" y=\"-575.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"94.38,-568.25 94.38,-602.25 161.38,-602.25 161.38,-568.25 94.38,-568.25\"/>\n",
       "<text text-anchor=\"start\" x=\"99.38\" y=\"-581.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 3, 32, 32)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"177.5,-530 16.5,-530 16.5,-486 177.5,-486 177.5,-530\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16.5,-486 16.5,-530 59.5,-530 59.5,-486 16.5,-486\"/>\n",
       "<text text-anchor=\"start\" x=\"22.25\" y=\"-510.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-498.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-508 59.5,-530 102.5,-530 102.5,-508 59.5,-508\"/>\n",
       "<text text-anchor=\"start\" x=\"68.62\" y=\"-515.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-508 102.5,-530 177.5,-530 177.5,-508 102.5,-508\"/>\n",
       "<text text-anchor=\"start\" x=\"110\" y=\"-515.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 3, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-486 59.5,-508 102.5,-508 102.5,-486 59.5,-486\"/>\n",
       "<text text-anchor=\"start\" x=\"64.12\" y=\"-493.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-486 102.5,-508 177.5,-508 177.5,-486 102.5,-486\"/>\n",
       "<text text-anchor=\"start\" x=\"107.38\" y=\"-493.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-568.29C97,-560.4 97,-550.59 97,-541.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-541.31 97,-531.31 93.5,-541.31 100.5,-541.31\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"177.5,-450 16.5,-450 16.5,-406 177.5,-406 177.5,-450\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16.5,-406 16.5,-450 59.5,-450 59.5,-406 16.5,-406\"/>\n",
       "<text text-anchor=\"start\" x=\"27.12\" y=\"-430.5\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-418.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-428 59.5,-450 102.5,-450 102.5,-428 59.5,-428\"/>\n",
       "<text text-anchor=\"start\" x=\"68.62\" y=\"-435.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-428 102.5,-450 177.5,-450 177.5,-428 102.5,-428\"/>\n",
       "<text text-anchor=\"start\" x=\"107.38\" y=\"-435.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-406 59.5,-428 102.5,-428 102.5,-406 59.5,-406\"/>\n",
       "<text text-anchor=\"start\" x=\"64.12\" y=\"-413.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-406 102.5,-428 177.5,-428 177.5,-406 102.5,-406\"/>\n",
       "<text text-anchor=\"start\" x=\"107.38\" y=\"-413.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-486.1C97,-478.49 97,-469.7 97,-461.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-461.47 97,-451.47 93.5,-461.47 100.5,-461.47\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"177.5,-370 16.5,-370 16.5,-326 177.5,-326 177.5,-370\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16.5,-326 16.5,-370 59.5,-370 59.5,-326 16.5,-326\"/>\n",
       "<text text-anchor=\"start\" x=\"22.25\" y=\"-350.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-338.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-348 59.5,-370 102.5,-370 102.5,-348 59.5,-348\"/>\n",
       "<text text-anchor=\"start\" x=\"68.62\" y=\"-355.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-348 102.5,-370 177.5,-370 177.5,-348 102.5,-348\"/>\n",
       "<text text-anchor=\"start\" x=\"107.38\" y=\"-355.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 24, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-326 59.5,-348 102.5,-348 102.5,-326 59.5,-326\"/>\n",
       "<text text-anchor=\"start\" x=\"64.12\" y=\"-333.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-326 102.5,-348 177.5,-348 177.5,-326 102.5,-326\"/>\n",
       "<text text-anchor=\"start\" x=\"107.38\" y=\"-333.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-406.1C97,-398.49 97,-389.7 97,-381.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-381.47 97,-371.47 93.5,-381.47 100.5,-381.47\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"177.5,-290 16.5,-290 16.5,-246 177.5,-246 177.5,-290\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16.5,-246 16.5,-290 59.5,-290 59.5,-246 16.5,-246\"/>\n",
       "<text text-anchor=\"start\" x=\"27.12\" y=\"-270.5\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-258.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-268 59.5,-290 102.5,-290 102.5,-268 59.5,-268\"/>\n",
       "<text text-anchor=\"start\" x=\"68.62\" y=\"-275.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-268 102.5,-290 177.5,-290 177.5,-268 102.5,-268\"/>\n",
       "<text text-anchor=\"start\" x=\"107.38\" y=\"-275.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-246 59.5,-268 102.5,-268 102.5,-246 59.5,-246\"/>\n",
       "<text text-anchor=\"start\" x=\"64.12\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-246 102.5,-268 177.5,-268 177.5,-246 102.5,-246\"/>\n",
       "<text text-anchor=\"start\" x=\"107.38\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 32, 32) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-326.1C97,-318.49 97,-309.7 97,-301.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-301.47 97,-291.47 93.5,-301.47 100.5,-301.47\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"177.5,-210 16.5,-210 16.5,-166 177.5,-166 177.5,-210\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16.5,-166 16.5,-210 59.5,-210 59.5,-166 16.5,-166\"/>\n",
       "<text text-anchor=\"start\" x=\"23.38\" y=\"-190.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Flatten</text>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-178.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-188 59.5,-210 102.5,-210 102.5,-188 59.5,-188\"/>\n",
       "<text text-anchor=\"start\" x=\"68.62\" y=\"-195.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-188 102.5,-210 177.5,-210 177.5,-188 102.5,-188\"/>\n",
       "<text text-anchor=\"start\" x=\"107.38\" y=\"-195.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12, 32, 32) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"59.5,-166 59.5,-188 102.5,-188 102.5,-166 59.5,-166\"/>\n",
       "<text text-anchor=\"start\" x=\"64.12\" y=\"-173.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102.5,-166 102.5,-188 177.5,-188 177.5,-166 102.5,-166\"/>\n",
       "<text text-anchor=\"start\" x=\"116\" y=\"-173.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12288) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-246.1C97,-238.49 97,-229.7 97,-221.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-221.47 97,-211.47 93.5,-221.47 100.5,-221.47\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"169,-130 25,-130 25,-86 169,-86 169,-130\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"25,-86 25,-130 68,-130 68,-86 25,-86\"/>\n",
       "<text text-anchor=\"start\" x=\"33.38\" y=\"-110.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"30\" y=\"-98.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"68,-108 68,-130 111,-130 111,-108 68,-108\"/>\n",
       "<text text-anchor=\"start\" x=\"77.12\" y=\"-115.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"111,-108 111,-130 169,-130 169,-108 111,-108\"/>\n",
       "<text text-anchor=\"start\" x=\"116\" y=\"-115.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 12288) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"68,-86 68,-108 111,-108 111,-86 68,-86\"/>\n",
       "<text text-anchor=\"start\" x=\"72.62\" y=\"-93.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"111,-86 111,-108 169,-108 169,-86 111,-86\"/>\n",
       "<text text-anchor=\"start\" x=\"123.88\" y=\"-93.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 10) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-166.1C97,-158.49 97,-149.7 97,-141.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-141.47 97,-131.47 93.5,-141.47 100.5,-141.47\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"150.5,-50 43.5,-50 43.5,-16 150.5,-16 150.5,-50\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"43.5,-16 43.5,-50 111.25,-50 111.25,-16 43.5,-16\"/>\n",
       "<text text-anchor=\"start\" x=\"48.5\" y=\"-35.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"60.88\" y=\"-23.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"111.25,-16 111.25,-50 150.5,-50 150.5,-16 111.25,-16\"/>\n",
       "<text text-anchor=\"start\" x=\"116.25\" y=\"-29.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 10)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-86.28C97,-78.46 97,-69.45 97,-61.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-61.18 97,-51.18 93.5,-61.18 100.5,-61.18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x204da34ce90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CNN().to(device)\n",
    "\n",
    "print('model is on:', next(model.parameters()).device)\n",
    "\n",
    "model_graph = draw_graph(model, input_size=(1, 3, 32, 32), expand_nested=True) # device='meta', \n",
    "model_graph.visual_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ec2c169-836b-4c22-8b78-5afbe47cc121",
   "metadata": {},
   "source": [
    "## CIFAR 10 dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d339502-4b34-4d4c-9faa-b459a6956bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ../data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare CIFAR-10 dataset\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "\n",
    "dataset = CIFAR10(\"../data/\", download=True, train=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8f495-510f-4bfe-a11e-28c0a33cf4a8",
   "metadata": {},
   "source": [
    "pyTorch中的dataset类型（包括各种内置公开数据集和ImageFolder等返回的数据集对象），具有`classes`和`class_to_idx`两个属性，可以方便得到类别名称和字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba132e8-2318-48c9-b220-3ad9e6241afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch    50: 0.091\n",
      "Loss after mini-batch   100: 0.092\n",
      "Loss after mini-batch   150: 0.093\n",
      "Loss after mini-batch   200: 0.094\n",
      "Loss after mini-batch   250: 0.093\n",
      "Loss after mini-batch   300: 0.096\n",
      "Loss after mini-batch   350: 0.094\n",
      "acc = 0.67282\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    50: 0.087\n",
      "Loss after mini-batch   100: 0.087\n",
      "Loss after mini-batch   150: 0.087\n",
      "Loss after mini-batch   200: 0.088\n",
      "Loss after mini-batch   250: 0.088\n",
      "Loss after mini-batch   300: 0.093\n",
      "Loss after mini-batch   350: 0.091\n",
      "acc = 0.69126\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    50: 0.081\n",
      "Loss after mini-batch   100: 0.084\n",
      "Loss after mini-batch   150: 0.084\n",
      "Loss after mini-batch   200: 0.084\n",
      "Loss after mini-batch   250: 0.086\n",
      "Loss after mini-batch   300: 0.086\n",
      "Loss after mini-batch   350: 0.083\n",
      "acc = 0.70666\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    50: 0.077\n",
      "Loss after mini-batch   100: 0.080\n",
      "Loss after mini-batch   150: 0.080\n",
      "Loss after mini-batch   200: 0.084\n",
      "Loss after mini-batch   250: 0.083\n",
      "Loss after mini-batch   300: 0.083\n",
      "Loss after mini-batch   350: 0.082\n",
      "acc = 0.71618\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    50: 0.076\n",
      "Loss after mini-batch   100: 0.077\n",
      "Loss after mini-batch   150: 0.076\n",
      "Loss after mini-batch   200: 0.077\n",
      "Loss after mini-batch   250: 0.081\n",
      "Loss after mini-batch   300: 0.079\n",
      "Loss after mini-batch   350: 0.078\n",
      "acc = 0.73018\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    50: 0.071\n",
      "Loss after mini-batch   100: 0.072\n",
      "Loss after mini-batch   150: 0.073\n",
      "Loss after mini-batch   200: 0.076\n",
      "Loss after mini-batch   250: 0.074\n",
      "Loss after mini-batch   300: 0.078\n",
      "Loss after mini-batch   350: 0.077\n",
      "acc = 0.7425\n",
      "Starting epoch 7\n",
      "Loss after mini-batch    50: 0.066\n",
      "Loss after mini-batch   100: 0.069\n",
      "Loss after mini-batch   150: 0.070\n",
      "Loss after mini-batch   200: 0.074\n",
      "Loss after mini-batch   250: 0.073\n",
      "Loss after mini-batch   300: 0.074\n",
      "Loss after mini-batch   350: 0.074\n",
      "acc = 0.75308\n",
      "Starting epoch 8\n",
      "Loss after mini-batch    50: 0.063\n",
      "Loss after mini-batch   100: 0.064\n",
      "Loss after mini-batch   150: 0.069\n",
      "Loss after mini-batch   200: 0.070\n",
      "Loss after mini-batch   250: 0.071\n",
      "Loss after mini-batch   300: 0.070\n",
      "Loss after mini-batch   350: 0.071\n",
      "acc = 0.76432\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    50: 0.060\n",
      "Loss after mini-batch   100: 0.064\n",
      "Loss after mini-batch   150: 0.064\n",
      "Loss after mini-batch   200: 0.065\n",
      "Loss after mini-batch   250: 0.068\n",
      "Loss after mini-batch   300: 0.066\n",
      "Loss after mini-batch   350: 0.067\n",
      "acc = 0.77508\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    50: 0.059\n",
      "Loss after mini-batch   100: 0.059\n",
      "Loss after mini-batch   150: 0.060\n",
      "Loss after mini-batch   200: 0.061\n",
      "Loss after mini-batch   250: 0.062\n",
      "Loss after mini-batch   300: 0.065\n",
      "Loss after mini-batch   350: 0.065\n",
      "acc = 0.787\n",
      "Starting epoch 11\n",
      "Loss after mini-batch    50: 0.058\n",
      "Loss after mini-batch   100: 0.056\n",
      "Loss after mini-batch   150: 0.057\n",
      "Loss after mini-batch   200: 0.058\n",
      "Loss after mini-batch   250: 0.062\n",
      "Loss after mini-batch   300: 0.061\n",
      "Loss after mini-batch   350: 0.062\n",
      "acc = 0.79544\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    50: 0.053\n",
      "Loss after mini-batch   100: 0.055\n",
      "Loss after mini-batch   150: 0.054\n",
      "Loss after mini-batch   200: 0.057\n",
      "Loss after mini-batch   250: 0.058\n",
      "Loss after mini-batch   300: 0.060\n",
      "Loss after mini-batch   350: 0.060\n",
      "acc = 0.80452\n",
      "Starting epoch 13\n",
      "Loss after mini-batch    50: 0.050\n",
      "Loss after mini-batch   100: 0.051\n",
      "Loss after mini-batch   150: 0.054\n",
      "Loss after mini-batch   200: 0.052\n",
      "Loss after mini-batch   250: 0.059\n",
      "Loss after mini-batch   300: 0.055\n",
      "Loss after mini-batch   350: 0.057\n",
      "acc = 0.81304\n",
      "Starting epoch 14\n",
      "Loss after mini-batch    50: 0.047\n",
      "Loss after mini-batch   100: 0.049\n",
      "Loss after mini-batch   150: 0.050\n",
      "Loss after mini-batch   200: 0.052\n",
      "Loss after mini-batch   250: 0.052\n",
      "Loss after mini-batch   300: 0.055\n",
      "Loss after mini-batch   350: 0.053\n",
      "acc = 0.82392\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    50: 0.046\n",
      "Loss after mini-batch   100: 0.045\n",
      "Loss after mini-batch   150: 0.048\n",
      "Loss after mini-batch   200: 0.049\n",
      "Loss after mini-batch   250: 0.049\n",
      "Loss after mini-batch   300: 0.052\n",
      "Loss after mini-batch   350: 0.051\n",
      "acc = 0.83314\n",
      "Starting epoch 16\n",
      "Loss after mini-batch    50: 0.041\n",
      "Loss after mini-batch   100: 0.046\n",
      "Loss after mini-batch   150: 0.046\n",
      "Loss after mini-batch   200: 0.047\n",
      "Loss after mini-batch   250: 0.046\n",
      "Loss after mini-batch   300: 0.050\n",
      "Loss after mini-batch   350: 0.047\n",
      "acc = 0.84244\n",
      "Starting epoch 17\n",
      "Loss after mini-batch    50: 0.041\n",
      "Loss after mini-batch   100: 0.039\n",
      "Loss after mini-batch   150: 0.042\n",
      "Loss after mini-batch   200: 0.045\n",
      "Loss after mini-batch   250: 0.046\n",
      "Loss after mini-batch   300: 0.046\n",
      "Loss after mini-batch   350: 0.048\n",
      "acc = 0.85098\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    50: 0.037\n",
      "Loss after mini-batch   100: 0.039\n",
      "Loss after mini-batch   150: 0.039\n",
      "Loss after mini-batch   200: 0.042\n",
      "Loss after mini-batch   250: 0.042\n",
      "Loss after mini-batch   300: 0.045\n",
      "Loss after mini-batch   350: 0.046\n",
      "acc = 0.85786\n",
      "Starting epoch 19\n",
      "Loss after mini-batch    50: 0.034\n",
      "Loss after mini-batch   100: 0.037\n",
      "Loss after mini-batch   150: 0.038\n",
      "Loss after mini-batch   200: 0.040\n",
      "Loss after mini-batch   250: 0.041\n",
      "Loss after mini-batch   300: 0.041\n",
      "Loss after mini-batch   350: 0.043\n",
      "acc = 0.86816\n",
      "Starting epoch 20\n",
      "Loss after mini-batch    50: 0.034\n",
      "Loss after mini-batch   100: 0.034\n",
      "Loss after mini-batch   150: 0.036\n",
      "Loss after mini-batch   200: 0.039\n",
      "Loss after mini-batch   250: 0.038\n",
      "Loss after mini-batch   300: 0.039\n",
      "Loss after mini-batch   350: 0.040\n",
      "acc = 0.87468\n",
      "Starting epoch 21\n",
      "Loss after mini-batch    50: 0.033\n",
      "Loss after mini-batch   100: 0.033\n",
      "Loss after mini-batch   150: 0.032\n",
      "Loss after mini-batch   200: 0.036\n",
      "Loss after mini-batch   250: 0.036\n",
      "Loss after mini-batch   300: 0.037\n",
      "Loss after mini-batch   350: 0.039\n",
      "acc = 0.88086\n",
      "Starting epoch 22\n",
      "Loss after mini-batch    50: 0.031\n",
      "Loss after mini-batch   100: 0.030\n",
      "Loss after mini-batch   150: 0.033\n",
      "Loss after mini-batch   200: 0.032\n",
      "Loss after mini-batch   250: 0.036\n",
      "Loss after mini-batch   300: 0.037\n",
      "Loss after mini-batch   350: 0.037\n",
      "acc = 0.88638\n",
      "Starting epoch 23\n",
      "Loss after mini-batch    50: 0.028\n",
      "Loss after mini-batch   100: 0.029\n",
      "Loss after mini-batch   150: 0.031\n",
      "Loss after mini-batch   200: 0.033\n",
      "Loss after mini-batch   250: 0.032\n",
      "Loss after mini-batch   300: 0.035\n",
      "Loss after mini-batch   350: 0.036\n",
      "acc = 0.89234\n",
      "Starting epoch 24\n",
      "Loss after mini-batch    50: 0.025\n",
      "Loss after mini-batch   100: 0.028\n",
      "Loss after mini-batch   150: 0.029\n",
      "Loss after mini-batch   200: 0.031\n",
      "Loss after mini-batch   250: 0.031\n",
      "Loss after mini-batch   300: 0.032\n",
      "Loss after mini-batch   350: 0.032\n",
      "acc = 0.90174\n",
      "Starting epoch 25\n",
      "Loss after mini-batch    50: 0.024\n",
      "Loss after mini-batch   100: 0.024\n",
      "Loss after mini-batch   150: 0.026\n",
      "Loss after mini-batch   200: 0.028\n",
      "Loss after mini-batch   250: 0.030\n",
      "Loss after mini-batch   300: 0.029\n",
      "Loss after mini-batch   350: 0.032\n",
      "acc = 0.90908\n",
      "Starting epoch 26\n",
      "Loss after mini-batch    50: 0.022\n",
      "Loss after mini-batch   100: 0.023\n",
      "Loss after mini-batch   150: 0.026\n",
      "Loss after mini-batch   200: 0.025\n",
      "Loss after mini-batch   250: 0.029\n",
      "Loss after mini-batch   300: 0.028\n",
      "Loss after mini-batch   350: 0.029\n",
      "acc = 0.91504\n",
      "Starting epoch 27\n",
      "Loss after mini-batch    50: 0.021\n",
      "Loss after mini-batch   100: 0.022\n",
      "Loss after mini-batch   150: 0.025\n",
      "Loss after mini-batch   200: 0.024\n",
      "Loss after mini-batch   250: 0.025\n",
      "Loss after mini-batch   300: 0.028\n",
      "Loss after mini-batch   350: 0.027\n",
      "acc = 0.91912\n",
      "Starting epoch 28\n",
      "Loss after mini-batch    50: 0.021\n",
      "Loss after mini-batch   100: 0.022\n",
      "Loss after mini-batch   150: 0.021\n",
      "Loss after mini-batch   200: 0.023\n",
      "Loss after mini-batch   250: 0.024\n",
      "Loss after mini-batch   300: 0.024\n",
      "Loss after mini-batch   350: 0.026\n",
      "acc = 0.92476\n",
      "Starting epoch 29\n",
      "Loss after mini-batch    50: 0.018\n",
      "Loss after mini-batch   100: 0.020\n",
      "Loss after mini-batch   150: 0.019\n",
      "Loss after mini-batch   200: 0.021\n",
      "Loss after mini-batch   250: 0.022\n",
      "Loss after mini-batch   300: 0.024\n",
      "Loss after mini-batch   350: 0.026\n",
      "acc = 0.92788\n",
      "Starting epoch 30\n",
      "Loss after mini-batch    50: 0.018\n",
      "Loss after mini-batch   100: 0.021\n",
      "Loss after mini-batch   150: 0.019\n",
      "Loss after mini-batch   200: 0.021\n",
      "Loss after mini-batch   250: 0.020\n",
      "Loss after mini-batch   300: 0.022\n",
      "Loss after mini-batch   350: 0.024\n",
      "acc = 0.93138\n",
      "Starting epoch 31\n",
      "Loss after mini-batch    50: 0.016\n",
      "Loss after mini-batch   100: 0.017\n",
      "Loss after mini-batch   150: 0.018\n",
      "Loss after mini-batch   200: 0.019\n",
      "Loss after mini-batch   250: 0.022\n",
      "Loss after mini-batch   300: 0.021\n",
      "Loss after mini-batch   350: 0.022\n",
      "acc = 0.93774\n",
      "Starting epoch 32\n",
      "Loss after mini-batch    50: 0.017\n",
      "Loss after mini-batch   100: 0.016\n",
      "Loss after mini-batch   150: 0.016\n",
      "Loss after mini-batch   200: 0.017\n",
      "Loss after mini-batch   250: 0.018\n",
      "Loss after mini-batch   300: 0.019\n",
      "Loss after mini-batch   350: 0.021\n",
      "acc = 0.94346\n",
      "Starting epoch 33\n",
      "Loss after mini-batch    50: 0.013\n",
      "Loss after mini-batch   100: 0.013\n",
      "Loss after mini-batch   150: 0.015\n",
      "Loss after mini-batch   200: 0.016\n",
      "Loss after mini-batch   250: 0.018\n",
      "Loss after mini-batch   300: 0.019\n",
      "Loss after mini-batch   350: 0.020\n",
      "acc = 0.94664\n",
      "Starting epoch 34\n",
      "Loss after mini-batch    50: 0.012\n",
      "Loss after mini-batch   100: 0.013\n",
      "Loss after mini-batch   150: 0.015\n",
      "Loss after mini-batch   200: 0.016\n",
      "Loss after mini-batch   250: 0.017\n",
      "Loss after mini-batch   300: 0.018\n",
      "Loss after mini-batch   350: 0.020\n",
      "acc = 0.949\n",
      "Starting epoch 35\n",
      "Loss after mini-batch    50: 0.013\n",
      "Loss after mini-batch   100: 0.013\n",
      "Loss after mini-batch   150: 0.014\n",
      "Loss after mini-batch   200: 0.016\n",
      "Loss after mini-batch   250: 0.016\n",
      "Loss after mini-batch   300: 0.018\n",
      "Loss after mini-batch   350: 0.019\n",
      "acc = 0.94836\n",
      "Starting epoch 36\n",
      "Loss after mini-batch    50: 0.013\n",
      "Loss after mini-batch   100: 0.014\n",
      "Loss after mini-batch   150: 0.013\n",
      "Loss after mini-batch   200: 0.015\n",
      "Loss after mini-batch   250: 0.014\n",
      "Loss after mini-batch   300: 0.016\n",
      "Loss after mini-batch   350: 0.016\n",
      "acc = 0.95424\n",
      "Starting epoch 37\n",
      "Loss after mini-batch    50: 0.011\n",
      "Loss after mini-batch   100: 0.011\n",
      "Loss after mini-batch   150: 0.011\n",
      "Loss after mini-batch   200: 0.012\n",
      "Loss after mini-batch   250: 0.013\n",
      "Loss after mini-batch   300: 0.015\n",
      "Loss after mini-batch   350: 0.015\n",
      "acc = 0.96154\n",
      "Starting epoch 38\n",
      "Loss after mini-batch    50: 0.010\n",
      "Loss after mini-batch   100: 0.012\n",
      "Loss after mini-batch   150: 0.011\n",
      "Loss after mini-batch   200: 0.013\n",
      "Loss after mini-batch   250: 0.014\n",
      "Loss after mini-batch   300: 0.013\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # Adam - 某种梯度下降算法，此处不展开; lr - learning rate\n",
    "model.train()\n",
    "\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(0, 50):\n",
    "    \n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    \n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "\n",
    "    corrects = 0\n",
    "    \n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "      \n",
    "        # Get inputs\n",
    "        inputs, targets = data # X & y\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "        \n",
    "        # Perform backward pass\n",
    "        loss.backward() # 后向传播，计算所有参数的偏导数\n",
    "        \n",
    "        # Perform optimization\n",
    "        optimizer.step() # 根据偏导数更新各个参数\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corrects += torch.sum(preds == targets.data)\n",
    "        \n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 50 == 49:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                (i + 1, current_loss / 500))\n",
    "            loss_history.append(current_loss / 500)\n",
    "            current_loss = 0.0\n",
    "\n",
    "    acc = corrects.double().item() / len(dataset)\n",
    "    print('acc =', acc)\n",
    "    acc_history.append(acc)\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87304f9-1250-4f8a-914b-257cebf84015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86961ff-0339-4eb8-af36-e70d9f7181bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83033e21-9eb4-42ee-b1bd-dc828a02f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = CIFAR10(\"../data/\", train=False, download=True, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=1)\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495c649-2947-460f-bb07-2d8c729fa17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_rgb_images(model, dataloader, max_samples = 100):\n",
    "\n",
    "    model.eval()    \n",
    "    sample_cnt = 0\n",
    "    correct = 0\n",
    "    for inputs, labels in dataloader:\n",
    "    \n",
    "        if sample_cnt >= max_samples:\n",
    "            break\n",
    "        sample_cnt += len(labels)\n",
    "        \n",
    "        plt.figure(figsize=(10,len(inputs)/10+1))\n",
    "        for idx, img  in enumerate(inputs):\n",
    "            plt.subplot(int(len(inputs)/10)+1, 10, idx+1)       \n",
    "            # x = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "            plt.imshow(img.numpy().transpose(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        print('truth: \\n', labels)\n",
    "        print('prediction: \\n', preds)\n",
    "        correct += (preds == labels).float().sum()\n",
    "        \n",
    "    accuracy = 100 * correct / sample_cnt\n",
    "    print('classification accuracy (%) =', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d758f3-f521-435d-88d8-6b620c1fc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rgb_images(model, trainloader, max_samples = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45831497-5e83-4dc9-a136-480bbddcdd4a",
   "metadata": {},
   "source": [
    "1个epoch acc就超过了MLP。最终训练集acc达到 90%+  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769a776-9350-49b8-9f86-6acd7d7873bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rgb_images(model, testloader, max_samples = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d1012-7d74-422c-b391-aa3af981c97b",
   "metadata": {},
   "source": [
    "发现训练集和测试集上模型的表现差异过大，这意味着发生了过拟合。  \n",
    "\n",
    "后续改进，解决过拟合现象：\n",
    "1. 尝试添加正则化(weight_decay)\n",
    "2. 尝试更大的batch_size\n",
    "3. 划分验证集和early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb25b5-2998-468e-9230-937b2da1e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "ts = datetime.today().strftime('%Y%m%d%H')\n",
    "MODEL_NAME = 'cnn_cifar10_'+ ts + '.pth'\n",
    "torch.save(model, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab5edf-5e20-492c-9bad-4a748fbb3813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
